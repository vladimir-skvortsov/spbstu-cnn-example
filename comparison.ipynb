{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network (CNN) Demonstration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (2.3.0)\n",
      "Requirement already satisfied: torchvision in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (0.18.0)\n",
      "Requirement already satisfied: pandas in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: tqdm in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (4.66.2)\n",
      "Collecting pathlib\n",
      "  Using cached pathlib-1.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: filelock in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (from torch) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (from torch) (2.6.3)\n",
      "Requirement already satisfied: jinja2 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: numpy in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (from torchvision) (10.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (from sympy->torch) (1.3.0)\n",
      "Using cached pathlib-1.0.1-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: pathlib\n",
      "Successfully installed pathlib-1.0.1\n"
     ]
    }
   ],
   "source": [
    "! pip install torch torchvision pandas tqdm pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torchvision as tv\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feed-Forward Model Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardClassifier(nn.Module):\n",
    "  def __init__(self, input_shape, n_classes, hidden_units=1024, dropout_rate=0.25):\n",
    "    super(FeedForwardClassifier, self).__init__()\n",
    "\n",
    "    input_dim = reduce(lambda x, y: x * y, input_shape)\n",
    "\n",
    "    self.classifier = nn.Sequential(\n",
    "      nn.Flatten(),\n",
    "\n",
    "      nn.Linear(input_dim, hidden_units),\n",
    "      nn.ReLU(),\n",
    "      nn.Dropout(dropout_rate),\n",
    "\n",
    "      nn.Linear(hidden_units, hidden_units),\n",
    "      nn.ReLU(),\n",
    "      nn.Dropout(dropout_rate),\n",
    "\n",
    "      nn.Linear(hidden_units, n_classes),\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    return self.classifier(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Model Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNClassifier(nn.Module):\n",
    "  def __init__(self, input_shape, n_classes, cnn_hidden_units=32, linear_hidden_units=1024, dropout_rate=0.25):\n",
    "    super(CNNClassifier, self).__init__()\n",
    "\n",
    "    self.conv_block1 = nn.Sequential(\n",
    "      nn.Conv2d(input_shape[0], cnn_hidden_units, kernel_size=3, padding=1),\n",
    "      nn.ReLU(),\n",
    "      nn.Conv2d(cnn_hidden_units, cnn_hidden_units, kernel_size=3, padding=1),\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "      nn.Dropout(dropout_rate),\n",
    "    )\n",
    "    self.conv_block2 = nn.Sequential(\n",
    "      nn.Conv2d(cnn_hidden_units, cnn_hidden_units, kernel_size=3, padding=1),\n",
    "      nn.ReLU(),\n",
    "      nn.Conv2d(cnn_hidden_units, cnn_hidden_units, kernel_size=3, padding=1),\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d(kernel_size=2),\n",
    "      nn.Dropout(dropout_rate),\n",
    "    )\n",
    "    self.classifier = nn.Sequential(\n",
    "      nn.Flatten(),\n",
    "      nn.Linear(cnn_hidden_units * 7 * 7, linear_hidden_units),\n",
    "      nn.Dropout(dropout_rate),\n",
    "      nn.Sigmoid(),\n",
    "      nn.Linear(linear_hidden_units, n_classes),\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.conv_block1(x)\n",
    "    x = self.conv_block2(x)\n",
    "\n",
    "    x = x.view(x.size(0), -1)\n",
    "\n",
    "    x = self.classifier(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Accuracy Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_fn(y_true, y_pred):\n",
    "  correct = torch.eq(y_true, y_pred).sum().item()\n",
    "  acc = (correct / len(y_pred)) * 100\n",
    "  return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup PyTorch device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = (\n",
    "  'cuda'\n",
    "  if torch.cuda.is_available()\n",
    "  else 'mps'\n",
    "  if torch.backends.mps.is_available()\n",
    "  else 'cpu'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Function for Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, data_loader, loss_fn, accuracy_fn):\n",
    "  loss, acc = 0, 0\n",
    "\n",
    "  model.eval()\n",
    "\n",
    "  with torch.inference_mode():\n",
    "    for x, y in data_loader:\n",
    "      x, y = x.to(device), y.to(device)\n",
    "\n",
    "      y_pred = model(x)\n",
    "\n",
    "      loss += loss_fn(y_pred, y)\n",
    "      acc += accuracy_fn(y_true=y, y_pred=y_pred.argmax(dim=1))\n",
    "\n",
    "    loss /= len(data_loader)\n",
    "    acc /= len(data_loader)\n",
    "\n",
    "  return {'name': model.__class__.__name__, 'loss': loss.item(), 'acc': acc}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Function for Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_params(model):\n",
    "  total_params = 0\n",
    "\n",
    "  for param in list(model.parameters()):\n",
    "    num_elements = 1\n",
    "\n",
    "    for size in list(param.size()):\n",
    "      num_elements *= size\n",
    "\n",
    "    total_params += num_elements\n",
    "\n",
    "  return total_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Experiment Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_datasets = (datasets.EMNIST, datasets.FashionMNIST, datasets.CIFAR100)\n",
    "models = (FeedForwardClassifier, CNNClassifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Datasets:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Epochs: 100%|██████████| 10/10 [01:06<00:00,  6.66s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Epochs: 100%|██████████| 10/10 [01:37<00:00,  9.75s/it]\n",
      "Models: 100%|██████████| 2/2 [02:45<00:00, 82.81s/it]\n",
      "Datasets:  33%|███▎      | 1/3 [02:45<05:31, 165.65s/it]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Epochs: 100%|██████████| 10/10 [01:02<00:00,  6.26s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Epochs: 100%|██████████| 10/10 [01:34<00:00,  9.43s/it]\n",
      "Models: 100%|██████████| 2/2 [02:38<00:00, 79.15s/it]\n",
      "Datasets:  67%|██████▋   | 2/3 [05:23<02:41, 161.33s/it]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Epochs: 100%|██████████| 10/10 [01:04<00:00,  6.49s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Epochs: 100%|██████████| 10/10 [01:38<00:00,  9.80s/it]\n",
      "Models: 100%|██████████| 2/2 [02:44<00:00, 82.28s/it]\n",
      "Datasets: 100%|██████████| 3/3 [08:08<00:00, 162.85s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>n_params</th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EMNIST</td>\n",
       "      <td>FeedForwardClassifier</td>\n",
       "      <td>1863690</td>\n",
       "      <td>0.317993</td>\n",
       "      <td>88.278754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EMNIST</td>\n",
       "      <td>CNNClassifier</td>\n",
       "      <td>1644970</td>\n",
       "      <td>0.251149</td>\n",
       "      <td>91.902955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FashionMNIST</td>\n",
       "      <td>FeedForwardClassifier</td>\n",
       "      <td>1863690</td>\n",
       "      <td>0.343027</td>\n",
       "      <td>87.699681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FashionMNIST</td>\n",
       "      <td>CNNClassifier</td>\n",
       "      <td>1644970</td>\n",
       "      <td>0.274849</td>\n",
       "      <td>90.674920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>FeedForwardClassifier</td>\n",
       "      <td>1863690</td>\n",
       "      <td>0.322914</td>\n",
       "      <td>88.428514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CIFAR100</td>\n",
       "      <td>CNNClassifier</td>\n",
       "      <td>1644970</td>\n",
       "      <td>0.292897</td>\n",
       "      <td>90.684904</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        dataset                  model  n_params      loss        acc\n",
       "0        EMNIST  FeedForwardClassifier   1863690  0.317993  88.278754\n",
       "1        EMNIST          CNNClassifier   1644970  0.251149  91.902955\n",
       "2  FashionMNIST  FeedForwardClassifier   1863690  0.343027  87.699681\n",
       "3  FashionMNIST          CNNClassifier   1644970  0.274849  90.674920\n",
       "4      CIFAR100  FeedForwardClassifier   1863690  0.322914  88.428514\n",
       "5      CIFAR100          CNNClassifier   1644970  0.292897  90.684904"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = Path('data')\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "results_df = pd.DataFrame()\n",
    "\n",
    "for Dataset in tqdm(example_datasets, desc='Datasets'):\n",
    "  train_data = datasets.FashionMNIST(\n",
    "    root=data_dir / Dataset.__name__,\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=tv.transforms.ToTensor(),\n",
    "    target_transform=None,\n",
    "  )\n",
    "  test_data = datasets.FashionMNIST(\n",
    "    root=data_dir / Dataset.__name__,\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=tv.transforms.ToTensor(),\n",
    "  )\n",
    "\n",
    "  image, label = train_data[0]\n",
    "  input_shape = image.shape\n",
    "  class_names = train_data.classes\n",
    "\n",
    "  train_dataloader = DataLoader(\n",
    "    dataset=train_data,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "  )\n",
    "  test_dataloader = DataLoader(\n",
    "    dataset=test_data,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "  )\n",
    "\n",
    "  for Model in tqdm(models, desc='Models'):\n",
    "    model = Model(input_shape=image.shape, n_classes=len(class_names)).to(device)\n",
    "    n_params = get_n_params(model)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(params=model.parameters(), lr=0.1)\n",
    "\n",
    "    for epoch in tqdm(range(epochs), desc='Epochs'):\n",
    "      train_loss = 0\n",
    "\n",
    "      for batch, (x, y) in enumerate(train_dataloader):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        y_pred = model(x)\n",
    "\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "      train_loss /= len(train_dataloader)\n",
    "\n",
    "      test_loss, test_acc = 0, 0\n",
    "\n",
    "      model.eval()\n",
    "\n",
    "      with torch.inference_mode():\n",
    "        for x, y in test_dataloader:\n",
    "          x, y = x.to(device), y.to(device)\n",
    "\n",
    "          test_pred = model(x)\n",
    "\n",
    "          test_loss += loss_fn(test_pred, y)\n",
    "\n",
    "          test_acc += accuracy_fn(y_true=y, y_pred=test_pred.argmax(dim=1))\n",
    "\n",
    "          test_loss /= len(test_dataloader)\n",
    "          test_acc /= len(test_dataloader)\n",
    "\n",
    "    results = eval_model(model, test_dataloader, loss_fn, accuracy_fn)\n",
    "    row = pd.DataFrame({\n",
    "      'dataset': Dataset.__name__,\n",
    "      'model': Model.__name__,\n",
    "      'n_params': n_params,\n",
    "      'loss': results['loss'],\n",
    "      'acc': results['acc'],\n",
    "    }, index=[0])\n",
    "    results_df = pd.concat([results_df, row], ignore_index=True)\n",
    "\n",
    "results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
